## Overview
A curated survey of OCR in the era of large language models, covering visual text parsing, understanding, benchmarks, challenges, and perspective. Paper is coming soon. 


## ðŸŽ‰ News
- **[2026-2-11]** ðŸ”¥ We release an open-source resource to help the community easily track recent OCR research!

## ðŸ“– Contents
- [News](#-news)
- [Visual Text Parsing](#-visual-text-parsing)
- [Visual Text Understanding](#-visual-text-understanding)
- [Benchmarks and Evaluation](#-benchmarks-and-evaluation)

## ðŸ“„ Visual Text Parsing
| Venue | Name | Primary affiliation | Title  | GitHub | Date |
|:-:|:-:|:-:|:-:|:-:|:-:|
| [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2510.19817) |  `OLMOCR 2` | Allen Institute for AI  | olmOCR 2: Unit Test Rewards for Document OCR |  [![GitHub Stars](https://img.shields.io/github/stars/allenai/olmocr?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/allenai/olmocr) | Oct. 2025 |
| [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2510.19817)  |  `Chandra v0.1.0` |   | -  | [![GitHub Stars](https://img.shields.io/github/stars/datalab-to/chandra?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/datalab-to/chandra)  |  Oct. 2025 |

## ðŸ“„ Visual Text Understanding
| Venue | Name | Primary affiliation | Title  | GitHub | Date |
|:-:|:-:|:-:|:-:|:-:|:-:|
| <a href="https://aclanthology.org/2025.acl-long.291/"><img src="./figs/ACL-logo.png" width="80"></a> | `mPLUG-DocOwl2` | Alibaba Group | mPLUG-DocOwl2: High-resolution Compressing for OCR-free Multi-page Document Understanding | [![GitHub Stars](https://img.shields.io/github/stars/X-PLUG/mPLUG-DocOwl?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/X-PLUG/mPLUG-DocOwl/tree/main/DocOwl2) | Sept. 2024 |

## ðŸ“„ Benchmarks and Evaluation

| Venue | Benchmark Name | Description  | Link | Date |
|:-:|:-:|:-:|:-:|:-:|
|XX| Omnidocbench (v1.5)  | Contains 1355 PDF pages and over 100,000 fine-grained annotations (70k+ span-level, 20k+ block-level). Compared to v1.0, it balances the ratio of Chinese/English pages and increases the resolution of some document types. | [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging%20Face-yellow)](https://huggingface.co/datasets/opendatalab/OmniDocBench/tree/main) [![GitHub](https://img.shields.io/github/stars/opendatalab/OmniDocBench?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/opendatalab/OmniDocBench) |



## Contributing
We welcome contributions from the community and encourage pull requests to help keep this project up to date. Please do not hesitate to contact me at ylliu@hust.edu.cn
 if you need any assistance.
